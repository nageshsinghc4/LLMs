{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY6kfYrmbVG8",
        "outputId": "5ec6bd2c-b989-41d9-8356-175476d7c164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-2.4.0-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff~=2.2.1 (from dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib~=1.3.2 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.3.2)\n",
            "Collecting openai<2.0.0,>=0.28.1 (from dspy-ai)\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.5.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2023.12.25)\n",
            "Collecting ujson (from dspy-ai)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (4.66.2)\n",
            "Collecting datasets<3.0.0,~=2.14.6 (from dspy-ai)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2.31.0)\n",
            "Collecting optuna (from dspy-ai)\n",
            "  Downloading optuna-3.6.0-py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==2.5.0 (from dspy-ai)\n",
            "  Downloading pydantic-2.5.0-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.5.0->dspy-ai) (0.6.0)\n",
            "Collecting pydantic-core==2.14.1 (from pydantic==2.5.0->dspy-ai)\n",
            "  Downloading pydantic_core-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.5.0->dspy-ai) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (2024.2.2)\n",
            "Collecting alembic>=1.5.0 (from optuna->dspy-ai)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->dspy-ai)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy-ai) (2.0.29)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2023.4)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->dspy-ai)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=0.28.1->dspy-ai) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (4.0.3)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets<3.0.0,~=2.14.6->dspy-ai) (3.13.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->dspy-ai) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->dspy-ai) (3.0.3)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->dspy-ai) (2.1.5)\n",
            "Installing collected packages: xxhash, ujson, pydantic-core, Mako, h11, dill, colorlog, backoff, pydantic, multiprocess, httpcore, alembic, optuna, httpx, openai, datasets, dspy-ai\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.16.3\n",
            "    Uninstalling pydantic_core-2.16.3:\n",
            "      Successfully uninstalled pydantic_core-2.16.3\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 backoff-2.2.1 colorlog-6.8.2 datasets-2.14.7 dill-0.3.7 dspy-ai-2.4.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 multiprocess-0.70.15 openai-1.14.3 optuna-3.6.0 pydantic-2.5.0 pydantic-core-2.14.1 ujson-5.9.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "%pip install dspy-ai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Hop Question Answering"
      ],
      "metadata": {
        "id": "-m5-xVA8dLmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A single search query is often not enough for complex QA tasks. For instance, an example within HotPotQA includes a question about the birth city of the writer of \"Right Back At It Again\". A search query often identifies the author correctly as \"Jeremy McKinnon\", but lacks the capability to compose the intended answer in determining when he was born.\n",
        "\n",
        "The standard approach for this challenge in retrieval-augmented NLP literature is to build multi-hop search systems, like GoldEn (Qi et al., 2019) and Baleen (Khattab et al., 2021). These systems read the retrieved results and then generate additional queries to gather additional information when necessary before arriving to a final answer. Using DSPy, we can easily simulate such systems in a few lines of code."
      ],
      "metadata": {
        "id": "2pQxNMUndTyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "turbo = dspy.OpenAI(model='gpt-3.5-turbo', api_key= '****')\n",
        "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
        "\n",
        "dspy.settings.configure(lm=turbo, rm=colbertv2_wiki17_abstracts)"
      ],
      "metadata": {
        "id": "ADW4TI4ndOMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "t3lu48bgdbqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using HotPotQA dataset, a collection of complex question-answer pairs typically answered in a multi-hop fashion."
      ],
      "metadata": {
        "id": "zRy-AbUwdgoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.datasets import HotPotQA\n",
        "\n",
        "# Load the dataset.\n",
        "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n",
        "\n",
        "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
        "trainset = [x.with_inputs('question') for x in dataset.train]\n",
        "devset = [x.with_inputs('question') for x in dataset.dev]\n",
        "\n",
        "len(trainset), len(devset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9hPWbx6dYs6",
        "outputId": "9d3453a7-488a-40b7-bbe0-8b8d5c8a3898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Signature"
      ],
      "metadata": {
        "id": "KQx5ev44dr5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start defining the signatures for sub-tasks of out Baleen pipeline.\n",
        "\n",
        "We'll start by creating the GenerateAnswer signature that'll take context and question as input and give answer as output."
      ],
      "metadata": {
        "id": "5XA2luUadw44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerateAnswer(dspy.Signature):\n",
        "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
        "\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
      ],
      "metadata": {
        "id": "ylUhzvYSdlvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike usual QA pipelines, we have an intermediate question-generation step in Baleen for which we'll need to define a new Signature for the \"hop\" behavior: inputting some context and a question to generate a search query to find missing information."
      ],
      "metadata": {
        "id": "P7zwf-tWeCQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerateSearchQuery(dspy.Signature):\n",
        "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
        "\n",
        "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
        "    question = dspy.InputField()\n",
        "    query = dspy.OutputField()"
      ],
      "metadata": {
        "id": "nViKHcN-d94v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the necessary signatures in place, we can start building the Baleen pipeline!"
      ],
      "metadata": {
        "id": "0eFPmzCpeH5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Pipeline\n"
      ],
      "metadata": {
        "id": "hEwQA48FeLIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, let's define the program itself SimplifiedBaleen."
      ],
      "metadata": {
        "id": "IYcn1yZAePKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dsp.utils import deduplicate\n",
        "\n",
        "class SimplifiedBaleen(dspy.Module):\n",
        "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
        "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
        "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
        "        self.max_hops = max_hops\n",
        "\n",
        "    def forward(self, question):\n",
        "        context = []\n",
        "\n",
        "        for hop in range(self.max_hops):\n",
        "            query = self.generate_query[hop](context=context, question=question).query\n",
        "            passages = self.retrieve(query).passages\n",
        "            context = deduplicate(context + passages)\n",
        "\n",
        "        pred = self.generate_answer(context=context, question=question)\n",
        "        return dspy.Prediction(context=context, answer=pred.answer)"
      ],
      "metadata": {
        "id": "KiFO3BwmeETu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the __init__ method defines a few key sub-modules:\n",
        "\n",
        "**generate_query**: For each hop, we will have one dspy.ChainOfThought predictor with the GenerateSearchQuery signature.\n",
        "\n",
        "**retrieve**: This module will conduct the search using the generated queries over our defined ColBERT RM search index via the dspy.Retrieve module.\n",
        "\n",
        "**generate_answer**: This dspy.Predict module will be used with the GenerateAnswer signature to produce the final answer.\n",
        "\n",
        "The forward method uses these sub-modules in simple control flow.\n",
        "\n",
        "* First, we'll loop up to self.max_hops times.\n",
        "\n",
        "* In each iteration, we'll generate a search query using the predictor at self.generate_query[hop].\n",
        "\n",
        "* We'll retrieve the top-k passages using that query.\n",
        "\n",
        "* We'll add the (deduplicated) passages to our context accumulator.\n",
        "\n",
        "* After the loop, we'll use self.generate_answer to produce an answer.\n",
        "\n",
        "* We'll return a prediction with the retrieved context and predicted answer.\n",
        "\n"
      ],
      "metadata": {
        "id": "cqU4sB4IeUY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executing the Pipeline\n"
      ],
      "metadata": {
        "id": "BtnYzAMCexn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's execute this program in its zero-shot (uncompiled) setting.\n",
        "\n",
        "This doesn't necessarily imply the performance will be bad but rather that we're bottlenecked directly by the reliability of the underlying LM to understand our sub-tasks from minimal instructions. Often, this is perfectly fine when using the most expensive/powerful models (e.g., GPT-4) on the easiest and most standard tasks (e.g., answering simple questions about popular entities).\n",
        "\n"
      ],
      "metadata": {
        "id": "k5PSx5qwe1Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask any question you like to this simple RAG program.\n",
        "my_question = \"How many storeys are in the castle that David Gregory inherited?\"\n",
        "\n",
        "# Get the prediction. This contains `pred.context` and `pred.answer`.\n",
        "uncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\n",
        "pred = uncompiled_baleen(my_question)\n",
        "\n",
        "# Print the contexts and the answer.\n",
        "print(f\"Question: {my_question}\")\n",
        "print(f\"Predicted Answer: {pred.answer}\")\n",
        "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuNwugZeeRi_",
        "outputId": "577f7663-6ede-400f-d475-87aec3d28e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many storeys are in the castle that David Gregory inherited?\n",
            "Predicted Answer: five\n",
            "Retrieved Contexts (truncated): ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinn...', 'St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 del...', 'Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was origin...', 'Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy....', 'Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years....', 'Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotla...']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "turbo.inspect_history(n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvBx6p_ie3uD",
        "outputId": "18ac6341-511f-483c-aec4-4299ae6c9fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Write a simple search query that will help answer a complex question.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Context: may contain relevant facts\n",
            "\n",
            "Question: ${question}\n",
            "\n",
            "Reasoning: Let's think step by step in order to ${produce the query}. We ...\n",
            "\n",
            "Query: ${query}\n",
            "\n",
            "---\n",
            "\n",
            "Context: N/A\n",
            "\n",
            "Question: How many storeys are in the castle that David Gregory inherited?\n",
            "\n",
            "Reasoning: Let's think step by step in order to\u001b[32m find the answer. We know that David Gregory inherited a castle, so we need to search for information about the castle's structure.\n",
            "\n",
            "Query: \"Number of storeys in castle inherited by David Gregory\"\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Write a simple search query that will help answer a complex question.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Context: may contain relevant facts\n",
            "\n",
            "Question: ${question}\n",
            "\n",
            "Reasoning: Let's think step by step in order to ${produce the query}. We ...\n",
            "\n",
            "Query: ${query}\n",
            "\n",
            "---\n",
            "\n",
            "Context:\n",
            "[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»\n",
            "[2] «St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 deluxe rooms, 85 suites with kitchens, and 16 top-floor suites with balconies. The hotel, which changed hands in June 2015, has a life-size statue of Marilyn Monroe in the lobby.»\n",
            "[3] «Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was originally built in 1909 for the Tau Gamma Nu fraternity, but was purchased by the ICC in 1995. Gregory House is the only house in the organization that is expressly substance free. No tobacco, alcohol, or illicit drugs are allowed on the property. Gregory House has a maximum capacity of 29 members (by way of 13 single and 8 double capacity rooms) as of June 2008.»\n",
            "\n",
            "Question: How many storeys are in the castle that David Gregory inherited?\n",
            "\n",
            "Reasoning: Let's think step by step in order to\u001b[32m produce the query. We know that David Gregory inherited Kinnairdy Castle in 1664. To find out how many storeys the castle has, we need to search for information related to the castle's structure.\n",
            "\n",
            "Query: \"Kinnairdy Castle storeys\"\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Answer questions with short factoid answers.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Context: may contain relevant facts\n",
            "\n",
            "Question: ${question}\n",
            "\n",
            "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
            "\n",
            "Answer: often between 1 and 5 words\n",
            "\n",
            "---\n",
            "\n",
            "Context:\n",
            "[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»\n",
            "[2] «St. Gregory Hotel | The St. Gregory Hotel is a boutique hotel located in downtown Washington, D.C., in the United States. Established in 2000, the nine-floor hotel has 155 rooms, which includes 54 deluxe rooms, 85 suites with kitchens, and 16 top-floor suites with balconies. The hotel, which changed hands in June 2015, has a life-size statue of Marilyn Monroe in the lobby.»\n",
            "[3] «Karl D. Gregory Cooperative House | Karl D. Gregory Cooperative House is a member of the Inter-Cooperative Council at the University of Michigan. The structure that stands at 1617 Washtenaw was originally built in 1909 for the Tau Gamma Nu fraternity, but was purchased by the ICC in 1995. Gregory House is the only house in the organization that is expressly substance free. No tobacco, alcohol, or illicit drugs are allowed on the property. Gregory House has a maximum capacity of 29 members (by way of 13 single and 8 double capacity rooms) as of June 2008.»\n",
            "[4] «Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy.»\n",
            "[5] «Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years.»\n",
            "[6] «Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotland. The 16th-century Kinnaird Castle was converted in 1787 for use as the Kinnaird Head Lighthouse, the first lighthouse in Scotland to be lit by the Commissioners of Northern Lights. Kinnaird Castle and the nearby Winetower were described by W. Douglas Simpson as two of the nine castles of the Knuckle, referring to the rocky headland of north-east Aberdeenshire. Both buildings are category A listed buildings.»\n",
            "\n",
            "Question: How many storeys are in the castle that David Gregory inherited?\n",
            "\n",
            "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know from the context that David Gregory inherited Kinnairdy Castle. \n",
            "\n",
            "Answer: five\u001b[0m\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizing the Pipeline\n"
      ],
      "metadata": {
        "id": "52HrUtTqfxAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, a zero-shot approach quickly falls short for more specialized tasks, novel domains/settings, and more efficient (or open) models.\n",
        "\n",
        "To address this, DSPy offers compilation. Let's compile our multi-hop (SimplifiedBaleen) program.\n",
        "\n",
        "Let's first define our validation logic for compilation:\n",
        "\n",
        "The predicted answer matches the gold answer.\n",
        "The retrieved context contains the gold answer.\n",
        "None of the generated queries is rambling (i.e., none exceeds 100 characters in length).\n",
        "None of the generated queries is roughly repeated (i.e., none is within 0.8 or higher F1 score of earlier queries)."
      ],
      "metadata": {
        "id": "9viKd1_vfzpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_context_and_answer_and_hops(example, pred, trace=None):\n",
        "    if not dspy.evaluate.answer_exact_match(example, pred): return False\n",
        "    if not dspy.evaluate.answer_passage_match(example, pred): return False\n",
        "\n",
        "    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]\n",
        "\n",
        "    if max([len(h) for h in hops]) > 100: return False\n",
        "    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "XczWhfhkfsdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use one of the most basic teleprompters in DSPy, namely, BootstrapFewShot to optimize the predictors in pipeline with few-shot examples.\n",
        "\n"
      ],
      "metadata": {
        "id": "uJMd2b3ff4Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.teleprompt import BootstrapFewShot\n",
        "\n",
        "teleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\n",
        "compiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r71RiVPBf2S6",
        "outputId": "f54528f6-2360-4dd1-ca94-971c90232d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [01:53<00:00,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 3 full traces after 20 examples in round 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Pipeline\n"
      ],
      "metadata": {
        "id": "xBhCnb1Af9Af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now define our evaluation function and compare the performance of the uncompiled and compiled Baleen pipelines. While this devset does not serve as a completely reliable benchmark, it is instructive to use for this tutorial."
      ],
      "metadata": {
        "id": "bOV-sv1KgAaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dspy.evaluate.evaluate import Evaluate\n",
        "def gold_passages_retrieved(example, pred, trace=None):\n",
        "    gold_titles = set(map(dspy.evaluate.normalize_text, example['gold_titles']))\n",
        "    found_titles = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n",
        "\n",
        "    return gold_titles.issubset(found_titles)\n",
        "\n",
        "\n",
        "# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\n",
        "evaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
        "\n",
        "uncompiled_baleen_retrieval_score = evaluate_on_hotpotqa(uncompiled_baleen, metric=gold_passages_retrieved, display=False)\n",
        "\n",
        "compiled_baleen_retrieval_score = evaluate_on_hotpotqa(compiled_baleen, metric=gold_passages_retrieved)\n",
        "\n",
        "print(f\"## Retrieval Score for uncompiled Baleen: {uncompiled_baleen_retrieval_score}\")\n",
        "print(f\"## Retrieval Score for compiled Baleen: {compiled_baleen_retrieval_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "PuFAObSVf6pH",
        "outputId": "a3f7b1f0-a512-48a7-917f-7d247382e0b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 28 / 50  (56.0): 100%|██████████| 50/50 [04:42<00:00,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Metric: 28 / 50  (56.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cc5bd221390>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_e8cc6 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_e8cc6 td {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_e8cc6_row0_col0, #T_e8cc6_row0_col1, #T_e8cc6_row0_col2, #T_e8cc6_row0_col3, #T_e8cc6_row0_col4, #T_e8cc6_row0_col5, #T_e8cc6_row1_col0, #T_e8cc6_row1_col1, #T_e8cc6_row1_col2, #T_e8cc6_row1_col3, #T_e8cc6_row1_col4, #T_e8cc6_row1_col5, #T_e8cc6_row2_col0, #T_e8cc6_row2_col1, #T_e8cc6_row2_col2, #T_e8cc6_row2_col3, #T_e8cc6_row2_col4, #T_e8cc6_row2_col5, #T_e8cc6_row3_col0, #T_e8cc6_row3_col1, #T_e8cc6_row3_col2, #T_e8cc6_row3_col3, #T_e8cc6_row3_col4, #T_e8cc6_row3_col5, #T_e8cc6_row4_col0, #T_e8cc6_row4_col1, #T_e8cc6_row4_col2, #T_e8cc6_row4_col3, #T_e8cc6_row4_col4, #T_e8cc6_row4_col5 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "  word-wrap: break-word;\n",
              "  max-width: 400px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_e8cc6\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_e8cc6_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_e8cc6_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
              "      <th id=\"T_e8cc6_level0_col2\" class=\"col_heading level0 col2\" >gold_titles</th>\n",
              "      <th id=\"T_e8cc6_level0_col3\" class=\"col_heading level0 col3\" >context</th>\n",
              "      <th id=\"T_e8cc6_level0_col4\" class=\"col_heading level0 col4\" >pred_answer</th>\n",
              "      <th id=\"T_e8cc6_level0_col5\" class=\"col_heading level0 col5\" >gold_passages_retrieved</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_e8cc6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_e8cc6_row0_col0\" class=\"data row0 col0\" >Are both Cangzhou and Qionghai in the Hebei province of China?</td>\n",
              "      <td id=\"T_e8cc6_row0_col1\" class=\"data row0 col1\" >no</td>\n",
              "      <td id=\"T_e8cc6_row0_col2\" class=\"data row0 col2\" >{'Qionghai', 'Cangzhou'}</td>\n",
              "      <td id=\"T_e8cc6_row0_col3\" class=\"data row0 col3\" >['Cangzhou | Cangzhou () is a prefecture-level city in eastern Hebei province, People\\'s Republic of China. At the 2010 census, Cangzhou\\'s built-up (\"or metro\") area...</td>\n",
              "      <td id=\"T_e8cc6_row0_col4\" class=\"data row0 col4\" >No</td>\n",
              "      <td id=\"T_e8cc6_row0_col5\" class=\"data row0 col5\" >✔️ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8cc6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_e8cc6_row1_col0\" class=\"data row1 col0\" >Who conducts the draft in which Marc-Andre Fleury was drafted to the Vegas Golden Knights for the 2017-18 season?</td>\n",
              "      <td id=\"T_e8cc6_row1_col1\" class=\"data row1 col1\" >National Hockey League</td>\n",
              "      <td id=\"T_e8cc6_row1_col2\" class=\"data row1 col2\" >{'2017 NHL Expansion Draft', '2017–18 Pittsburgh Penguins season'}</td>\n",
              "      <td id=\"T_e8cc6_row1_col3\" class=\"data row1 col3\" >[\"2017 NHL Expansion Draft | The 2017 NHL Expansion Draft was an expansion draft conducted by the National Hockey League on June 18–20, 2017 to...</td>\n",
              "      <td id=\"T_e8cc6_row1_col4\" class=\"data row1 col4\" >National Hockey League</td>\n",
              "      <td id=\"T_e8cc6_row1_col5\" class=\"data row1 col5\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8cc6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_e8cc6_row2_col0\" class=\"data row2 col0\" >The Wings entered a new era, following the retirement of which Canadian retired professional ice hockey player and current general manager of the Tampa Bay...</td>\n",
              "      <td id=\"T_e8cc6_row2_col1\" class=\"data row2 col1\" >Steve Yzerman</td>\n",
              "      <td id=\"T_e8cc6_row2_col2\" class=\"data row2 col2\" >{'Steve Yzerman', '2006–07 Detroit Red Wings season'}</td>\n",
              "      <td id=\"T_e8cc6_row2_col3\" class=\"data row2 col3\" >['Doug Soetaert | Douglas Henry Soetaert (born April 21, 1955 in Edmonton, Alberta) is a retired Canadian professional ice hockey goaltender. In the 2016–17 season...</td>\n",
              "      <td id=\"T_e8cc6_row2_col4\" class=\"data row2 col4\" >Lou Lamoriello</td>\n",
              "      <td id=\"T_e8cc6_row2_col5\" class=\"data row2 col5\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8cc6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_e8cc6_row3_col0\" class=\"data row3 col0\" >What river is near the Crichton Collegiate Church?</td>\n",
              "      <td id=\"T_e8cc6_row3_col1\" class=\"data row3 col1\" >the River Tyne</td>\n",
              "      <td id=\"T_e8cc6_row3_col2\" class=\"data row3 col2\" >{'Crichton Castle', 'Crichton Collegiate Church'}</td>\n",
              "      <td id=\"T_e8cc6_row3_col3\" class=\"data row3 col3\" >[\"Crichton Collegiate Church | Crichton Collegiate Church is situated about 0.6 mi south west of the hamlet of Crichton in Midlothian, Scotland. Crichton itself is...</td>\n",
              "      <td id=\"T_e8cc6_row3_col4\" class=\"data row3 col4\" >River Tyne</td>\n",
              "      <td id=\"T_e8cc6_row3_col5\" class=\"data row3 col5\" >✔️ [True]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e8cc6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_e8cc6_row4_col0\" class=\"data row4 col0\" >In the 10th Century A.D. Ealhswith had a son called Æthelweard by which English king?</td>\n",
              "      <td id=\"T_e8cc6_row4_col1\" class=\"data row4 col1\" >King Alfred the Great</td>\n",
              "      <td id=\"T_e8cc6_row4_col2\" class=\"data row4 col2\" >{'Æthelweard (son of Alfred)', 'Ealhswith'}</td>\n",
              "      <td id=\"T_e8cc6_row4_col3\" class=\"data row4 col3\" >['Æthelweard (son of Alfred) | Æthelweard (d. 920 or 922) was the younger son of King Alfred the Great and Ealhswith.', 'Æthelweard (historian) | Æthelweard...</td>\n",
              "      <td id=\"T_e8cc6_row4_col4\" class=\"data row4 col4\" >King Alfred the Great</td>\n",
              "      <td id=\"T_e8cc6_row4_col5\" class=\"data row4 col5\" >✔️ [True]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "                <div style='\n",
              "                    text-align: center;\n",
              "                    font-size: 16px;\n",
              "                    font-weight: bold;\n",
              "                    color: #555;\n",
              "                    margin: 10px 0;'>\n",
              "                    ... 45 more rows not displayed ...\n",
              "                </div>\n",
              "                "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Retrieval Score for uncompiled Baleen: 44.0\n",
            "## Retrieval Score for compiled Baleen: 56.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHj0_0guh9Oe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}